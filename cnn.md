### CNN 개요
**컨볼루션 신경망(CNN, Convolutional Neural Network)** 은 이미지 데이터를 학습하는 대표적인 딥러닝 모델로, 컨볼루션 연산을 통해 중요한 특징을 추출하고, 풀링(pooling) 및 활성화 함수를 적용하여 점진적으로 추상적인 정보를 학습한다.

CNN의 주요 과정은 다음과 같다.
1. **컨볼루션(Convolution)** 을 통해 특징 맵(feature map) 생성
2. **활성화 함수(Activation Function, 예: ReLU)** 적용
3. **풀링(Pooling, 예: Max Pooling)** 을 통해 차원 축소
4. **완전 연결 신경망(Fully Connected Layer, FC Layer)** 을 거쳐 최종 예측 수행

### 컨볼루션 연산(Convolution Operation)
CNN의 핵심은 **컨볼루션 연산** 이며, 이는 입력 이미지 $$\( X \)$$ 와 필터(커널) $$\( W \)$$의 요소별 곱(sum of element-wise multiplication)으로 정의된다.

$$
\
Y(i, j) = \sum_m \sum_n X(i+m, j+n) W(m, n)
\
$$


- $$\ X(i, j) \$$ : 입력 이미지 픽셀 값  
- $$\ W(m, n) \$$ : 컨볼루션 필터(커널)  
- $$\ Y(i, j) \$$ : 컨볼루션 결과 값(특성 맵)

RGB 이미지의 경우, 각 픽셀 값은 Red(R), Green(G), Blue(B) 세 개의 채널 값을 가진다. 따라서 $$X(0,8)$$ 은 단일 스칼라 값이 아니라, 3개의 채널 값을 가진 벡터 형태이다.

RGB 이미지에서 픽셀 값 표현 만약 $$X(i,j)$$ 가 RGB 이미지라면, 특정 좌표의 픽셀 값은 다음과 같이 표현할 수 있다: $$X(0,8)=(R,G,B)$$


- $$X(0,8,0)$$ → Red (빨강)
- $$X(0,8,1)$$ → Green (초록)
- $$X(0,8,2)$$ → Blue (파랑)

RGB 이미지는 (Height, Width, Channels) 형태로 표현되는데, 예를 들어 256 × 256 256×256 크기의 컬러 이미지는 다음과 같은 3D 배열(텐서) 구조를 가진다:

$$X \in \mathbb{R}^{256 \times 256 \times 3}$$

즉, **256 x 256 픽셀 크기에 대해 3개의 채널(R, G, B)** 표현이 가능하며, 만약 $$X(0,8)=(255,100,50)$$ 라면, **빨강 (R) 값: 255 초록 (G) 값: 100 파랑 (B) 값: 50** 으로 정의된다.


### 컨볼루션에서 필터 이동 방식
필터가 $(i, j)$ 위치에 놓였다고 가정할 때, 필터 크기를 3×3 설정하자. $(i, j)$ 위치 주변의 3×3 영역을 선택한다. 즉, $(i, j)$를 기준으로 위, 아래, 좌, 우 픽셀을 포함한 3×3 영역을 가져온다.

### 3×3 크기의 필터를 적용할 때는 다음과 같이 반복 연산
필터의 각 원소 $W(m, n)$과, 입력 이미지에서 필터가 커버하는 영역의 픽셀 값 $X(i + m, j + n)$를 곱한다.

### 이렇게 계산된 값을 모두 더해서 $Y(i, j)$ 값 생성
공식은 다음과 같다:

$$
Y(i, j) = \sum_{m=0}^{2} \sum_{n=0}^{2} X(i+m, j+n) W(m, n)
$$

이 공식에서, $i + m$과 $j + n$은 필터 내부에서 선택된 픽셀 위치를 의미한다. 필터의 크기가 3×3이므로, $m$, $n$의 범위는 0~2(즉, 3개 픽셀),

$m = 0, 1, 2$와 $n = 0, 1, 2$를 반복하면서 총 9개의 픽셀 값을 필터와 곱한 후 더해준다.

다시, CNN 연산 순서 정리를 해보면 일반적으로 다음 과정을 반복하면서 특징을 추출한다.

#### 1️⃣ 컨볼루션 연산 (특성 맵 생성)
* 입력 이미지에서 **필터(커널)를 적용**하여 특성 맵을 생성한다.
* 입력 크기가 고정된 경우, 커널 크기와 출력 특성 맵 크기는 반비례 관계를 가진다.
* Feature map의 크기가 클수록(즉, 커널 크기가 작을수록) 더 세밀한 디테일을 표현할 수 있다.
* 이 과정에서 **엣지(경계), 질감, 패턴 등 중요한 특징을 학습**하게 된다.

#### 2️⃣ ReLU 활성화 함수 적용
* 컨볼루션 연산을 거친 값들은 **음수일 수도 있고 양수일 수도 있다**.
* 하지만 **음수 값은 특징을 나타내지 않는 경우가 많기 때문에 0으로 변환**한다.
* ReLU(Rectified Linear Unit) 활성화 함수는 아래처럼 동작한다:

$$f(x) = \max(0, x)$$

   * **양수 값은 그대로 유지**
   * **음수 값은 0으로 변환**

#### 📌 왜 여기서 ReLU를 적용할까?
   * **비선형성을 추가해서 모델이 더 복잡한 패턴을 학습할 수 있도록 도와준다.**
   * **음수 값을 제거해서 그레이디언트 소실 문제(vanishing gradient)를 방지한다.**

#### 3️⃣ 풀링 (Pooling)
* **특성 맵의 크기를 줄여서 연산량을 감소시키고, 중요한 특징을 유지하는 과정**.
* 가장 많이 사용하는 풀링 방법은 **Max Pooling (최대 풀링)**:

$$Y(i, j) = \max_{m, n} X(i+m, j+n)$$

   * 특정 영역(예: $2 \times 2$)에서 **최댓값만 남김**.
   * 작은 변화를 무시하고 **가장 중요한 특징만 유지**.
   * 모델이 **더 일반화될 수 있도록** 도와주어 **과적합 방지 효과**.

#### 4️⃣ 다시 특성 맵 생성 → ReLU → 풀링...
* 여러 개의 컨볼루션과 풀링 층을 반복적으로 적용해서 이미지에서 점점 더 **복잡한 특징을 학습**한다.
* 예를 들면:
   * 첫 번째 컨볼루션 레이어: **엣지(경계선) 검출** - 네트워크의 초기 층에서는 인접한 픽셀 값 간의 큰 차이를 감지하여 이미지의 경계선이나 윤곽선을 추출한다. 예: 밝은 영역과 어두운 영역의 경계, 색상의 차이가 뚜렷한 부분
   * 두 번째 컨볼루션 레이어: **질감 감지** - 더 깊은 층에서는 edge들이 모여 특정 패턴이나 질감을 형성하는 것을 학습한다. 예: 잔디밭의 미세한 반복 구조, 물체 표면의 질감
   * 세 번째 컨볼루션 레이어: **물체의 부분 학습** - 신경망이 더욱 깊어지면 질감 정보를 조합하여 눈, 코, 입과 같은 물체의 특정 부분을 인식할 수 있다.
   * 마지막 컨볼루션 레이어: **전체 물체 감지** - 가장 깊은 층에서는 이러한 부분들이 결합되어 전체 물체(예: 얼굴, 자동차, 동물 등)를 인식한다.

#### 📌 CNN의 전체 흐름
**컨볼루션 → ReLU → 풀링 → 컨볼루션 → ReLU → 풀링 → ... → Fully Connected Layer → Softmax**

1. **컨볼루션 (특성 맵 생성)**
2. **ReLU 활성화 함수 적용**
3. **풀링 (차원 축소)**
4. **컨볼루션**
5. **ReLU 활성화 함수 적용**
6. **풀링**
7. ... 반복 ...
8. **완전 연결 신경망 (FC Layer) → 소프트맥스 (Softmax)로 최종 예측**

#### 5️⃣ CNN의 최종 예측 단계
평탄화(flatten) → 완전 연결 신경망(fully connected layer, FC layer) → 소프트맥스(Softmax) 활성화 함수를 통해 최종 클래스를 예측한다. 결국 

소프트맥스 함수는 확률 값을 반환하며, 수식은 다음과 같다:
P(yi)=ezi∑jezjP(y_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}P(yi​)=∑j​ezj​ezi​​

$z_i$ : 뉴런의 활성화 값
$P(y_i)$ : 클래스 $i$에 대한 확률

CNN 모델의 마지막에는 보통 fully-connected layer(FC layer)가 위치하며, 이 전에 feature map을 1D 벡터로 변환하는 flatten layer가 배치된다. Local feature들은 특정 영역의 정보를 반영하지만, 최종 분류를 위해서는 전체적인 문맥을 고려한 확률 분포가 필요하다. 이를 위해 CNN에서는 fully-connected layer 또는 global pooling을 활용하여 feature map을 압축하고 최종 확률을 계산한다."


